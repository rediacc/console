{
  "version": "1.0",
  "generated": "2026-01-16T09:43:38Z",
  "total_templates": 27,
  "categories": [
    "analytics",
    "automation",
    "caching",
    "databases",
    "messaging",
    "monitoring",
    "networking",
    "platforms",
    "search"
  ],
  "templates": [
    {
      "id": "analytics_plausible",
      "name": "Plausible Community Edition",
      "description": "Lightweight, privacy-focused web analytics platform that respects user privacy while providing valuable insights.",
      "category": "analytics",
      "tags": ["analytics", "plausible"],
      "file_count": 5,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/analytics_plausible.json",
      "readme": "# Plausible Community Edition\n\nLightweight, privacy-focused web analytics platform that respects user privacy while providing valuable insights.\n\n## Features\n- Privacy-first analytics (GDPR, CCPA compliant, no cookies)\n- Lightweight tracking script (<1KB)\n- Real-time visitor statistics and pageview tracking\n- Self-hosted with full data ownership\n- Beautiful, simple dashboard interface\n- Built on PostgreSQL and ClickHouse for performance\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start Plausible (auto-generates secret key on first run)\ndown  # Stop and cleanup\n```\n\n### First Run - Auto-Configuration\nOn first run, a secret key is automatically generated:\n- **SECRET_KEY_BASE**: 64-byte encryption key for data security\n- **Secret File**: Saved to `./plausible-secret.txt`\n- **Initialization**: Database creation and migrations run automatically (~60 seconds)\n- **Admin Account**: Create on first visit to web interface\n\n**Important**: Keep the secret file secure - required for encryption!\n\n## Configuration\nEdit `.env` to customize:\n- `BASE_URL`: Your domain (default: http://localhost:8000)\n- `HTTP_PORT`: Container port (default: 8000)\n- `DISABLE_REGISTRATION`: Registration mode (default: invite_only)\n- `POSTGRES_PASSWORD`: Database password (default: postgres)\n\n### Email Configuration (Optional)\nFor user invites and password resets, configure SMTP in `.env`:\n- Uncomment and set `SMTP_HOST_ADDR`, `SMTP_HOST_PORT`, etc.\n- Or use third-party services (Postmark, Mailgun, SendGrid)\n\n## Access\n- **Web Interface**: Auto-assigned port (find with `docker compose ps`)\n  - Example: `http://localhost:<port>`\n- **Find Port**: Run `docker compose ps` and look for mapped port\n- **First Visit**: Create your admin account\n- **Startup Time**: Allow ~60 seconds for database initialization\n\n## Website Integration\nAfter setting up Plausible:\n\n1. **Create Site**: Add your website in the Plausible dashboard\n2. **Add Tracking Script**: Insert in your website's `<head>`:\n   ```html\n   <script defer data-domain=\"yourdomain.com\" src=\"http://your-plausible-url/js/script.js\"></script>\n   ```\n3. **Verify**: Visit your site and check the Plausible dashboard\n\n## Production Setup\nFor production deployments:\n\n1. **Domain Configuration**\n   - Set `BASE_URL` to your actual domain (e.g., https://analytics.example.com)\n   - Configure reverse proxy (Nginx/Caddy) with SSL/TLS\n\n2. **Email Setup**\n   - Configure SMTP for user invites and password resets\n   - Required for team collaboration features\n\n3. **Registration Mode**\n   - Set `DISABLE_REGISTRATION=true` after creating admin account\n   - Use invite-only mode for team members\n\n4. **Resource Requirements**\n   - Minimum 2GB RAM recommended\n   - CPU must support SSE 4.2 or NEON (ClickHouse requirement)\n\n## Important Notes\n- **SECRET_KEY_BASE**: Auto-generated on first run, stored in `./plausible-secret.txt`\n- **Data Persistence**: PostgreSQL data in `./postgres-data/`, ClickHouse in `./clickhouse-data/`\n- **Initialization**: First startup takes ~60 seconds for database setup\n- **BASE_URL**: Must match your actual domain for proper operation\n- **Port Assignment**: Container-only port (Docker assigns random host port to avoid conflicts)\n\n## Resources\n- [Official Documentation](https://plausible.io/docs/self-hosting)\n- [Docker Setup Guide](https://github.com/plausible/community-edition)\n- [Plausible Community](https://plausible.io/community)\n- [Integration Guides](https://plausible.io/docs/integration-guides)"
    },
    {
      "id": "automation_n8n",
      "name": "n8n Workflow Automation",
      "description": "Fair-code workflow automation tool for connecting apps and services with a visual interface.",
      "category": "automation",
      "tags": ["automation", "n8n"],
      "file_count": 5,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/automation_n8n.json",
      "readme": "# n8n Workflow Automation\n\nFair-code workflow automation tool for connecting apps and services with a visual interface.\n\n## Features\n- Visual workflow editor with 400+ integrations\n- Self-hosted with full data control\n- SQLite database (default) or PostgreSQL for production\n- Webhook support for external triggers\n- Scheduled workflow execution\n- Built-in error handling and debugging\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull image and create directory\nup    # Start n8n (auto-generates encryption key on first run)\ndown  # Stop and cleanup\n```\n\n### First Run - Auto-Configuration\nOn first run, an encryption key is automatically generated:\n- **Encryption Key**: Random 32-character key for credential security\n- **Credentials File**: Saved to `./n8n-data/encryption-key.txt`\n- **Admin Access**: Default username/password (see .env file)\n\n**Important**: Change the default admin password after first login!\n\n## Configuration\nEdit `.env` to customize:\n- `N8N_BASIC_AUTH_USER`: Admin username (default: admin)\n- `N8N_BASIC_AUTH_PASSWORD`: Admin password (default: change me!)\n- `GENERIC_TIMEZONE`: Timezone for workflow scheduling (default: UTC)\n- `N8N_PORT`: Container port (default: 5678)\n\n## Access\n- **Web Interface**: Auto-assigned port (find with `docker compose ps`)\n  - Example: `http://localhost:<port>`\n- **Default Credentials**: Check `.env` file (admin / changeme)\n- **Find Port**: Run `docker compose ps` and look for mapped port\n\n## Workflow Management\n- **Create**: Access web interface, click \"+\" to create new workflow\n- **Backup**: Data stored in `./n8n-data/` directory\n- **Import/Export**: Use web interface Tools → Import/Export\n- **Persistence**: All workflows saved automatically to local volume\n\n## Production Setup (Optional)\nFor production deployments, consider:\n\n1. **PostgreSQL Database** (better performance, scalability)\n   - Add PostgreSQL service to docker-compose.yaml\n   - Set `DB_TYPE=postgresdb` in environment\n\n2. **Redis Queue Mode** (for distributed execution)\n   - Add Redis service\n   - Set `EXECUTIONS_MODE=queue` and Redis connection details\n\n3. **Reverse Proxy** (SSL/TLS, custom domain)\n   - Configure Nginx/Caddy with Let's Encrypt\n   - Set `N8N_PROTOCOL=https` and `WEBHOOK_URL`\n\n4. **Resource Limits**\n   - Increase memory to 2-4GB for heavy workflows\n   - Add CPU limits in docker-compose.yaml\n\n## Important Notes\n- **Encryption Key**: Auto-generated on first run, stored in `./n8n-data/encryption-key.txt`\n- **Credentials File**: Keep this secure - required for n8n to decrypt stored credentials\n- **SQLite Database**: Default database, stored in `./n8n-data/database.sqlite`\n- **Data Persistence**: All workflows, credentials, and settings in `./n8n-data/`\n- **Port Assignment**: Container-only port (Docker assigns random host port to avoid conflicts)\n\n## Resources\n- [Official Documentation](https://docs.n8n.io/)\n- [Docker Installation Guide](https://docs.n8n.io/hosting/installation/docker/)\n- [n8n Community](https://community.n8n.io/)\n- [Workflow Templates](https://n8n.io/workflows/)"
    },
    {
      "id": "caching_memcached",
      "name": "Memcached Template",
      "description": "High-performance distributed memory caching system for speeding up dynamic web applications.",
      "category": "caching",
      "tags": ["caching", "memcached"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/caching_memcached.json",
      "readme": "# Memcached Template\n\nHigh-performance distributed memory caching system for speeding up dynamic web applications.\n\n## Features\n\n- In-memory caching with configurable memory allocation\n- Multi-threaded support for high concurrency\n- Connection limit control and health monitoring\n- LRU eviction policy for automatic memory management\n- Lightweight and fast with no persistent storage\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start Memcached\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n\n- `CONTAINER_NAME`: Container name (default: memcached-server)\n- `MEMCACHED_MEMORY`: Memory limit in MB (default: 64)\n- `MEMCACHED_THREADS`: Number of threads (default: 4)\n- `MEMCACHED_MAX_CONN`: Maximum connections (default: 1024)\n- `MEMCACHED_VERBOSITY`: Verbosity level, use \"v\" or \"vv\" for verbose (default: empty)\n\n## Access\n\n- **Port**: 11211 (Docker auto-assigns host port)\n- **Protocol**: TCP/UDP\n- **Find assigned port**: `docker compose ps`\n\n### Testing Connection\n\n```bash\n# Using docker exec\ndocker exec memcached-server sh -c 'echo \"stats\" | nc localhost 11211'\n\n# Using telnet (replace <port> with assigned port)\ntelnet localhost <port>\nstats\nquit\n```\n\n### Common Commands\n\n```bash\n# Get server statistics\ndocker exec memcached-server sh -c 'echo \"stats\" | nc localhost 11211'\n\n# Flush all data\ndocker exec memcached-server sh -c 'echo \"flush_all\" | nc localhost 11211'\n\n# Monitor logs\ndocker logs -f memcached-server\n```\n\n## Resources\n\n- [Official Docker Hub](https://hub.docker.com/_/memcached)\n- [Memcached Documentation](https://memcached.org/)\n- [Memcached Wiki](https://github.com/memcached/memcached/wiki)"
    },
    {
      "id": "caching_redis",
      "name": "Redis Cache Template",
      "description": "High-performance, in-memory data structure store used as a database, cache, and message broker.",
      "category": "caching",
      "tags": ["caching", "redis"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/caching_redis.json",
      "readme": "# Redis Cache Template\n\nHigh-performance, in-memory data structure store used as a database, cache, and message broker.\n\n## Features\n\n- Redis 7 Alpine (lightweight and fast)\n- Password authentication with configurable credentials\n- Configurable memory limits with LRU eviction policy\n- Persistent data storage with health checks\n- Isolated network for security\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start Redis server\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n\n- `CONTAINER_NAME`: Container name (default: redis-server)\n- `REDIS_PORT`: Port mapping (default: 6379)\n- `REDIS_PASSWORD`: Authentication password (required)\n- `REDIS_MAXMEMORY`: Memory limit (default: 256mb)\n- `REDIS_MAXMEMORY_POLICY`: Eviction policy (default: allkeys-lru)\n\n## Access\n\n- **Port**: 6379 (Docker auto-assigns host port)\n- **Password**: Set in `.env` file (`REDIS_PASSWORD`)\n- **Find assigned port**: `docker compose ps`\n\nConnect using redis-cli:\n```bash\n# Using redis-cli\nredis-cli -h localhost -p 6379 -a yourPassword\n\n# Using Docker exec\ndocker exec -it redis-server redis-cli -a yourPassword\n```\n\n## Resources\n\n- [Official Docker Hub](https://hub.docker.com/_/redis)\n- [Official Documentation](https://redis.io/docs/)"
    },
    {
      "id": "databases_arangodb",
      "name": "ArangoDB Multi-Model Database",
      "description": "A native multi-model database with flexible data models for documents, graphs, and key-value pairs. Build high-performance applications using a convenient SQL-like query language or JavaScript extensions.",
      "category": "databases",
      "tags": ["databases", "arangodb"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_arangodb.json",
      "readme": "# ArangoDB Multi-Model Database\n\nA native multi-model database with flexible data models for documents, graphs, and key-value pairs. Build high-performance applications using a convenient SQL-like query language or JavaScript extensions.\n\n## Features\n\n- Multi-model support (document, graph, key-value)\n- Built-in web interface for administration\n- AQL query language (SQL-like)\n- Authentication enabled by default\n- Persistent data storage with health checks\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start ArangoDB\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n- `CONTAINER_NAME`: Container name (default: arangodb-server)\n- `ARANGO_ROOT_PASSWORD`: Root password for database access (required)\n- `ARANGODB_OVERRIDE_DETECTED_TOTAL_MEMORY`: Memory limit (default: auto-detect)\n- `ARANGODB_OVERRIDE_DETECTED_NUMBER_OF_CORES`: CPU cores limit (default: auto-detect)\n\n## Access\n\n- **Port**: 8529 (Docker auto-assigns host port)\n- **Web Interface**: Access via assigned port with username `root`\n- **Password**: Check `ARANGO_ROOT_PASSWORD` in `.env`\n- **Find assigned port**: `docker compose ps`\n\n### CLI Access\n```bash\n# Access ArangoDB shell\ndocker exec -it arangodb-server arangosh --server.password yourRootPassword123!\n\n# Connection string for applications\nhttp://root:yourRootPassword123!@localhost:8529\n```\n\n### Quick AQL Examples\n```javascript\n// Create database and collection\ndb._createDatabase(\"myapp\");\ndb._useDatabase(\"myapp\");\ndb._create(\"users\");\n\n// Query with AQL\ndb._query('FOR user IN users FILTER user.age >= 18 RETURN user');\n```\n\n## Resources\n\n- [Official Docker Hub](https://hub.docker.com/_/arangodb)\n- [Official Documentation](https://docs.arangodb.com/)\n- [AQL Tutorial](https://docs.arangodb.com/stable/aql/)"
    },
    {
      "id": "databases_cassandra",
      "name": "Apache Cassandra Database Template",
      "description": "Distributed NoSQL database designed for handling large amounts of data with high availability and no single point of failure.",
      "category": "databases",
      "tags": ["databases", "cassandra"],
      "file_count": 5,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_cassandra.json",
      "readme": "# Apache Cassandra Database Template\n\nDistributed NoSQL database designed for handling large amounts of data with high availability and no single point of failure.\n\n## Features\n\n- Apache Cassandra 5.0 with authentication enabled\n- Persistent data storage with automatic initialization\n- CQL shell access and client connectivity\n- Health checks for container readiness\n- Sample keyspace and schema included\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start Cassandra\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n- `CONTAINER_NAME`: Container name (default: cassandra-db)\n- `CASSANDRA_CLUSTER_NAME`: Cluster name (default: MyCluster)\n- `CASSANDRA_DC`: Datacenter name (default: datacenter1)\n- `CASSANDRA_RACK`: Rack name (default: rack1)\n- `CASSANDRA_ENDPOINT_SNITCH`: Snitch implementation (default: GossipingPropertyFileSnitch)\n- `CASSANDRA_NUM_TOKENS`: Number of tokens (default: 256)\n- `CASSANDRA_AUTHENTICATOR`: Authentication method (default: PasswordAuthenticator)\n- `CASSANDRA_AUTHORIZER`: Authorization method (default: CassandraAuthorizer)\n\n**Default credentials:** Username `cassandra`, Password `cassandra` (change in production)\n\n## Access\n\n**Port:** 9042 (Docker auto-assigns host port)\n\n**Find assigned port:**\n```bash\ndocker compose ps\n```\n\n**CQL Shell:**\n```bash\ndocker exec -it cassandra-db cqlsh -u cassandra -p cassandra\n```\n\n**Connection details:**\n- Host: localhost\n- Username: cassandra\n- Password: cassandra\n- Datacenter: datacenter1\n- Keyspace: myapp (pre-created)\n\n**Check cluster status:**\n```bash\ndocker exec -it cassandra-db nodetool status\n```\n\n**Note:** Cassandra takes 30-60 seconds to fully start. Wait for \"Created default superuser role\" in logs.\n\n## Resources\n\n- [Official Docker Hub](https://hub.docker.com/_/cassandra)\n- [Official Documentation](https://cassandra.apache.org/doc/latest/)\n- [CQL Reference](https://cassandra.apache.org/doc/latest/cassandra/cql/)\n- [DataStax Drivers](https://docs.datastax.com/en/driver-matrix/docs/index.html)"
    },
    {
      "id": "databases_couchdb",
      "name": "Apache CouchDB Database Template",
      "description": "NoSQL document database with HTTP JSON API, multi-master replication, and optional web-based admin interface (Fauxton).",
      "category": "databases",
      "tags": ["databases", "couchdb"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_couchdb.json",
      "readme": "# Apache CouchDB Database Template\n\nNoSQL document database with HTTP JSON API, multi-master replication, and optional web-based admin interface (Fauxton).\n\n## Features\n\n- CouchDB 3.x with built-in Fauxton web UI\n- RESTful HTTP/JSON API for documents\n- Admin authentication and cluster-ready setup\n- Health checks and persistent data storage\n- Multi-master replication support\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start CouchDB\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n- `CONTAINER_NAME`: Container name (default: couchdb-server)\n- `COUCHDB_USER`: Admin username (default: admin)\n- `COUCHDB_PASSWORD`: Admin password (required)\n- `COUCHDB_SECRET`: Cluster authentication secret (auto-generated)\n\n## Access\n\n- **Port**: 5984 (Docker auto-assigns host port)\n- **Web UI**: http://localhost:5984/_utils (Fauxton)\n- **Credentials**: See `.env` for username/password\n- **Find assigned port**: `docker compose ps` or `docker port couchdb-server 5984`\n\n**Quick API Test:**\n```bash\n# Check server status\ncurl http://localhost:5984/\n\n# Create database (use credentials from .env)\ncurl -X PUT http://admin:yourPassword@localhost:5984/mydb\n```\n\n## Resources\n\n- [CouchDB Docker Hub](https://hub.docker.com/_/couchdb)\n- [Official CouchDB Documentation](https://docs.couchdb.org/)\n- [HTTP API Guide](https://docs.couchdb.org/en/stable/api/index.html)\n- [Fauxton Interface](https://docs.couchdb.org/en/stable/fauxton/index.html)"
    },
    {
      "id": "databases_crate",
      "name": "CrateDB",
      "description": "A distributed SQL database designed for containerized environments with real-time analytics and scalability.",
      "category": "databases",
      "tags": ["databases", "crate"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_crate.json",
      "readme": "# CrateDB\n\nA distributed SQL database designed for containerized environments with real-time analytics and scalability.\n\n## Features\n- PostgreSQL wire protocol compatible for easy integration\n- Optimized for time-series data and real-time analytics\n- Built-in web admin UI for management and queries\n- Single-node mode for development and testing\n- Automatic port assignment to avoid conflicts\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull image and create data directory\nup    # Start CrateDB server\ndown  # Stop and cleanup\n```\n\n## Configuration\nEdit `.env` to customize:\n- `CONTAINER_NAME`: Container name (default: cratedb-server)\n- `CRATE_HEAP_SIZE`: JVM heap size, set to ~50% of container memory (default: 1g)\n- `CLUSTER_NAME`: Cluster identifier (default: crate-docker-cluster)\n\nData persists in `./data` directory.\n\n## Access\n- **Admin UI**: Port 4200 (Docker auto-assigns host port)\n- **PostgreSQL Protocol**: Port 5432 (Docker auto-assigns host port)\n- **HTTP API**: Port 4200 (same as Admin UI)\n- **Find assigned port**: `docker compose ps`\n\nConnect via PostgreSQL client:\n```bash\npsql -h localhost -p <assigned-port> -U crate\n```\n\nAccess Admin UI at `http://localhost:<assigned-port>`\n\n## Resources\n- [Official Docker Hub](https://hub.docker.com/_/crate)\n- [Official Documentation](https://cratedb.com/docs)\n- [SQL Reference](https://cratedb.com/docs/crate/reference/en/latest/sql/index.html)\n- [PostgreSQL Compatibility](https://cratedb.com/docs/crate/reference/en/latest/interfaces/postgres.html)"
    },
    {
      "id": "databases_influxdb",
      "name": "InfluxDB Time Series Database",
      "description": "High-performance time series database optimized for fast, high-availability storage and retrieval of time series data.",
      "category": "databases",
      "tags": ["databases", "influxdb"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_influxdb.json",
      "readme": "# InfluxDB Time Series Database\n\nHigh-performance time series database optimized for fast, high-availability storage and retrieval of time series data.\n\n## Features\n\n- InfluxDB 2.7 with built-in web UI and API\n- Automated initial setup with authentication\n- Flux query language for data analysis\n- Persistent data storage in local directories\n- Optimized for IoT, metrics, and monitoring data\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start InfluxDB\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n\n- `CONTAINER_NAME`: Container name (default: influxdb-server)\n- `INFLUXDB_INIT_USERNAME`: Admin username (default: admin)\n- `INFLUXDB_INIT_PASSWORD`: Admin password (default: influxPassword123!)\n- `INFLUXDB_INIT_ORG`: Organization name (default: myorg)\n- `INFLUXDB_INIT_BUCKET`: Default bucket name (default: mybucket)\n- `INFLUXDB_INIT_RETENTION`: Data retention period (default: 0 - infinite)\n- `INFLUXDB_INIT_ADMIN_TOKEN`: API admin token (auto-generated if not set)\n\n## Access\n\n**Web Interface:**\n- **Port**: 8086 (Docker auto-assigns host port)\n- **Credentials**: Check `.env` file for username/password\n- **Find assigned port**: `docker compose ps`\n\n**API Access:**\n```bash\n# Retrieve admin token from logs\ndocker logs influxdb-server 2>&1 | grep \"token\"\n\n# Write data\ncurl -X POST http://localhost:8086/api/v2/write?org=myorg&bucket=mybucket \\\n  -H \"Authorization: Token YOUR_ADMIN_TOKEN\" \\\n  -H \"Content-Type: text/plain\" \\\n  --data-raw \"temperature,location=room1 value=23.5\"\n\n# Query data using Flux\ncurl -X POST http://localhost:8086/api/v2/query?org=myorg \\\n  -H \"Authorization: Token YOUR_ADMIN_TOKEN\" \\\n  -H \"Content-Type: application/vnd.flux\" \\\n  --data 'from(bucket:\"mybucket\") |> range(start:-1h)'\n```\n\n**CLI Access:**\n```bash\ndocker exec -it influxdb-server influx bucket list\ndocker exec -it influxdb-server influx query 'from(bucket:\"mybucket\") |> range(start:-1h)'\n```\n\n## Resources\n\n- [Official Docker Hub](https://hub.docker.com/_/influxdb)\n- [Official Documentation](https://docs.influxdata.com/influxdb/v2/)\n- [Flux Query Language Guide](https://docs.influxdata.com/flux/v0/)\n- [Migration from v1.x](https://docs.influxdata.com/influxdb/v2/upgrade/v1-to-v2/)"
    },
    {
      "id": "databases_mariadb",
      "name": "MariaDB Database Server",
      "description": "Production-ready MariaDB database server with persistent storage and automatic configuration.",
      "category": "databases",
      "tags": ["databases", "mariadb"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_mariadb.json",
      "readme": "# MariaDB Database Server\n\nProduction-ready MariaDB database server with persistent storage and automatic configuration.\n\n## Features\n- Persistent data storage with bind mounts\n- Health check monitoring\n- Initialization script support for automated schema setup\n- Custom configuration support via `.cnf` files\n- Optimized for production workloads\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull MariaDB image and create directories\nup    # Start MariaDB server\ndown  # Stop and cleanup\n```\n\n## Configuration\nEdit `.env` to customize:\n- `MARIADB_ROOT_PASSWORD`: Root user password (default: changeme)\n- `MARIADB_DATABASE`: Initial database name (default: appdb)\n- `MARIADB_USER`: Application user name (default: appuser)\n- `MARIADB_PASSWORD`: Application user password (default: changeme)\n\n**Custom Configuration**: Place `.cnf` files in `./config/` directory\n**Initialization Scripts**: Place SQL or shell scripts in `./init/` directory (executed alphabetically on first startup)\n\n## Access\n- **Port**: 3306 (Docker auto-assigns host port)\n- **Find assigned port**: `docker compose ps`\n- **Connect**: `mysql -h 127.0.0.1 -P <assigned-port> -u root -p`\n\n## Backup\n```bash\n# Full backup\ndocker compose exec db mariadb-dump -u root -p --all-databases > backup.sql\n\n# Restore\ndocker compose exec -T db mariadb -u root -p < backup.sql\n```\n\n## Resources\n- [Official Docker Hub](https://hub.docker.com/_/mariadb)\n- [Official Documentation](https://mariadb.com/kb/en/documentation/)\n- [Environment Variables](https://mariadb.com/kb/en/mariadb-docker-environment-variables/)"
    },
    {
      "id": "databases_mssql",
      "name": "Microsoft SQL Server Template",
      "description": "Quick deployment of Microsoft SQL Server 2022 using Docker.",
      "category": "databases",
      "tags": ["databases", "mssql"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_mssql.json",
      "readme": "# Microsoft SQL Server Template\n\nQuick deployment of Microsoft SQL Server 2022 using Docker.\n\n## Features\n- SQL Server 2022 Developer Edition with SQL Server Agent\n- Persistent storage for data, logs, and secrets\n- Configurable SA password and security settings\n- Health check monitoring included\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start SQL Server\ndown  # Stop and cleanup\n```\n\n## Configuration\nEdit `.env` to customize:\n- `MSSQL_SA_PASSWORD`: SA account password (default: yourStrong(!)Password)\n- `ACCEPT_EULA`: Accept MSSQL EULA (default: Y)\n- `MSSQL_PID`: Product ID/Edition (default: Developer)\n\n## Access\n- **Port**: 1433 (Docker auto-assigns host port)\n- **Credentials**: SA user with password from `.env`\n- **Find assigned port**: `docker compose ps`\n- **Connect**: `sqlcmd -S localhost,<port> -U sa -P '<password>'`\n\n## Resources\n- [Official Docker Hub](https://hub.docker.com/_/microsoft-mssql-server)\n- [Official Documentation](https://learn.microsoft.com/en-us/sql/linux/sql-server-linux-overview)"
    },
    {
      "id": "databases_mysql",
      "name": "MySQL/MariaDB Template",
      "description": "MariaDB database with phpMyAdmin web interface.",
      "category": "databases",
      "tags": ["databases", "mysql"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_mysql.json",
      "readme": "# MySQL/MariaDB Template\n\nMariaDB database with phpMyAdmin web interface.\n\n## Features\n- MariaDB 10.3 database server\n- phpMyAdmin for web-based administration\n- Persistent data storage with bind mounts\n- Isolated Docker network\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start MariaDB and phpMyAdmin\ndown  # Stop and cleanup\n```\n\n## Configuration\nEdit `.env` to customize:\n- `MYSQL_ROOT_PASSWORD`: Root user password (default: rootpassword)\n- `MYSQL_DATABASE`: Initial database name (default: myapp)\n- `MYSQL_USER`: Application user (default: user)\n- `MYSQL_PASSWORD`: Application password (default: password)\n\n## Access\n- **MySQL Port**: 3306 (Docker auto-assigns host port)\n- **phpMyAdmin**: Port 8080 (Docker auto-assigns host port)\n- **Credentials**: Check `.env` file\n- **Find assigned port**: `docker compose ps`\n\n## Connect\n```bash\n# Connect via MySQL client\nmysql -h localhost -P 3306 -u root -p\n\n# Or use phpMyAdmin web interface\ndocker compose ps  # Find phpMyAdmin port\n```\n\n## Resources\n- [Official Docker Hub - MariaDB](https://hub.docker.com/_/mariadb)\n- [Official Docker Hub - phpMyAdmin](https://hub.docker.com/_/phpmyadmin)\n- [MariaDB Documentation](https://mariadb.com/kb/en/documentation/)\n- [MySQL Documentation](https://dev.mysql.com/doc/)"
    },
    {
      "id": "databases_neo4j",
      "name": "Neo4j Graph Database",
      "description": "A powerful graph database platform for connected data with a built-in web interface (Neo4j Browser) for querying and visualization.",
      "category": "databases",
      "tags": ["databases", "neo4j"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_neo4j.json",
      "readme": "# Neo4j Graph Database\n\nA powerful graph database platform for connected data with a built-in web interface (Neo4j Browser) for querying and visualization.\n\n## Features\n\n- Neo4j Community Edition 5.x with Neo4j Browser web interface\n- APOC plugin pre-installed for extended functionality\n- Cypher query language with relationship traversal\n- Persistent data, logs, configuration, and plugins storage\n- Authentication enabled with configurable memory settings\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start Neo4j\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n\n- `CONTAINER_NAME`: Container name (default: neo4j-server)\n- `NEO4J_AUTH`: Username/password (default: neo4j/changeme123!)\n- `NEO4J_PLUGINS`: Additional plugins (default: [\"apoc\"])\n- `NEO4J_server_memory_heap_initial__size`: Initial heap size (default: 512M)\n- `NEO4J_server_memory_heap_max__size`: Maximum heap size (default: 1G)\n- `NEO4J_server_memory_pagecache_size`: Page cache size (default: 512M)\n\n## Access\n\n- **Neo4j Browser**: Port 7474 (Docker auto-assigns host port)\n- **Bolt Protocol**: Port 7687 for application connections\n- **Credentials**: Check `.env` file (default: neo4j/changeme123!)\n- **Find assigned ports**: `docker compose ps` or `docker port neo4j-server 7474`\n- **Cypher shell**: `docker exec -it neo4j-server cypher-shell -u neo4j -p changeme123!`\n\n## Resources\n\n- [Official Docker Hub](https://hub.docker.com/_/neo4j)\n- [Neo4j Documentation](https://neo4j.com/docs/)\n- [Cypher Query Language](https://neo4j.com/docs/cypher-manual/current/)\n- [APOC Documentation](https://neo4j.com/labs/apoc/)"
    },
    {
      "id": "databases_percona",
      "name": "Percona Server for MySQL",
      "description": "Enterprise-ready MySQL database server with enhanced performance, scalability, and diagnostics features.",
      "category": "databases",
      "tags": ["databases", "percona"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_percona.json",
      "readme": "# Percona Server for MySQL\n\nEnterprise-ready MySQL database server with enhanced performance, scalability, and diagnostics features.\n\n## Features\n- Drop-in replacement for MySQL with enterprise-grade enhancements\n- Superior performance and scalability over standard MySQL\n- Advanced diagnostics and monitoring capabilities\n- Full MySQL compatibility with zero application changes\n- Persistent storage with bind mounts\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull image and create data directory\nup    # Start Percona Server\ndown  # Stop and cleanup\n```\n\n## Configuration\nEdit `.env` to customize:\n- `MYSQL_ROOT_PASSWORD`: Root user password (default: notSecureChangeMe)\n- `MYSQL_DATABASE`: Database to create on first start (optional)\n- `MYSQL_USER`: Additional user to create (optional)\n- `MYSQL_PASSWORD`: Password for additional user (optional)\n\n**Security:** Change default passwords before deployment. Use `MYSQL_RANDOM_ROOT_PASSWORD=yes` for production.\n\n## Access\n- **Port**: 3306 (Docker auto-assigns host port)\n- **Credentials**: Check `.env` file\n- **Find assigned port**: `docker compose ps`\n- **Connect**: `mysql -h 127.0.0.1 -P <mapped-port> -u root -p`\n\n## Resources\n- [Official Docker Hub](https://hub.docker.com/_/percona)\n- [Percona Server Documentation](https://docs.percona.com/percona-server/8.0/)\n- [Feature Comparison](https://www.percona.com/software/mysql-database/percona-server)"
    },
    {
      "id": "databases_postgresql",
      "name": "PostgreSQL Template",
      "description": "High-performance PostgreSQL setup with benchmarking and automated configuration.",
      "category": "databases",
      "tags": ["databases", "postgresql"],
      "file_count": 5,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_postgresql.json",
      "readme": "# PostgreSQL Template\n\nHigh-performance PostgreSQL setup with benchmarking and automated configuration.\n\n## Features\n- Auto-detected container and dynamic port assignment\n- CPU-optimized threading (auto-detects cores, max 8)\n- Sysbench integration for OLTP performance testing\n- Bulk data generation for custom tables\n- One-command host setup for required tools\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start PostgreSQL\ndown  # Stop and cleanup\n```\n\n### Benchmarking\n```bash\n# Install sysbench and PostgreSQL client\n./postgres.sh host_setup\n\n# Initialize database and run benchmarks\nsource ./postgres.sh\n./postgres.sh create_database\n./postgres.sh initialize_sysbench    # Load 8×1M tables\n./postgres.sh benchmark_qps          # Run QPS test\n./postgres.sh cleanup_sysbench       # Remove test data\n```\n\n## Configuration\nEdit `.env` to customize:\n- `PGUSER`: PostgreSQL username (default: postgres)\n- `PGPASSWORD`: Database password (default: mysecretpassword)\n- `DBNAME`: Database name for benchmarks (default: sysbench_test)\n- `TABLES`: Number of sysbench tables (default: 8)\n- `TABLE_SIZE`: Rows per sysbench table (default: 1000000)\n\nContainer name and port are auto-detected. Threads auto-set to CPU cores (max 8).\n\n## Access\n- **Port**: 5432 (Docker auto-assigns host port)\n- **Credentials**: Check `.env` file\n- **Find assigned port**: `docker compose ps`\n- **Connect**: `psql -h 127.0.0.1 -p <host-port> -U postgres`\n\n## Resources\n- [Official Docker Hub](https://hub.docker.com/_/postgres)\n- [PostgreSQL Documentation](https://www.postgresql.org/docs/)\n- [Sysbench Documentation](https://github.com/akopytov/sysbench)"
    },
    {
      "id": "databases_rethinkdb",
      "name": "RethinkDB",
      "description": "RethinkDB is an open-source, distributed JSON database designed for real-time applications. Built for modern web and mobile apps, it delivers real-time updates through push architecture and offers an intuitive query language with a powerful administration interface.",
      "category": "databases",
      "tags": ["databases", "rethinkdb"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_rethinkdb.json",
      "readme": "# RethinkDB\n\nRethinkDB is an open-source, distributed JSON database designed for real-time applications. Built for modern web and mobile apps, it delivers real-time updates through push architecture and offers an intuitive query language with a powerful administration interface.\n\n## Features\n\n- **Real-time Push Architecture**: Automatically pushes data changes to applications in real-time\n- **JSON Document Store**: Schema-free, stores JSON documents natively with powerful ReQL query language\n- **Web-based Admin Interface**: Built-in administration console with Data Explorer and monitoring\n- **Geospatial Support**: Built-in geospatial indexing and queries for location-based applications\n- **Multi-language Drivers**: Official drivers for JavaScript, Python, Ruby, Java, and more\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start RethinkDB\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n- `CONTAINER_NAME`: Container name (default: rethinkdb)\n- `RETHINKDB_CACHE_SIZE`: Cache size in MB (default: 512)\n\nData is stored in `./data` directory and persists across container restarts.\n\n## Access\n\n- **Web Admin**: Port 8080 (Docker auto-assigns host port)\n- **Client Driver**: Port 28015 (for application connections)\n- **Cluster Port**: Port 29015 (for cluster setups)\n- **Find assigned ports**: `docker compose ps`\n\n### Connection Examples\n\n```javascript\n// Node.js\nconst r = require('rethinkdb');\nconst conn = await r.connect({ host: 'localhost', port: 28015, db: 'test' });\n```\n\n```python\n# Python\nimport rethinkdb as r\nconn = r.connect(host='localhost', port=28015, db='test')\n```\n\n### Quick Start with Data Explorer\n\n```javascript\n// Create database and table using web interface or driver\nr.dbCreate('myapp').run(conn);\nr.db('myapp').tableCreate('users').run(conn);\n\n// Insert data\nr.db('myapp').table('users').insert({\n  name: 'John Doe',\n  email: 'john@example.com',\n  created: r.now()\n}).run(conn);\n\n// Real-time updates\nr.db('myapp').table('users').changes().run(conn, (err, cursor) => {\n  cursor.each(console.log);  // Prints changes as they happen\n});\n```\n\n## Backup and Restore\n\n```bash\n# Backup\ndocker exec rethinkdb rethinkdb dump -f backup.tar.gz\n\n# Restore\ndocker exec rethinkdb rethinkdb restore backup.tar.gz\n```\n\n## Resources\n\n- [Official Docker Hub](https://hub.docker.com/_/rethinkdb)\n- [Official Documentation](https://rethinkdb.com/docs/)\n- [Ten-minute Guide](https://rethinkdb.com/docs/guide/javascript/)\n- [API Reference](https://rethinkdb.com/api/javascript/)"
    },
    {
      "id": "databases_solr",
      "name": "Apache Solr Search Platform",
      "description": "Enterprise search platform built on Apache Lucene with powerful full-text search, faceting, real-time indexing, and RESTful APIs.",
      "category": "databases",
      "tags": ["databases", "solr"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/databases_solr.json",
      "readme": "# Apache Solr Search Platform\n\nEnterprise search platform built on Apache Lucene with powerful full-text search, faceting, real-time indexing, and RESTful APIs.\n\n## Features\n\n- Apache Solr 9.x with built-in Admin UI\n- Full-text search with faceting and highlighting\n- RESTful HTTP/JSON API\n- Configurable cores with managed schema\n- Persistent data storage with health checks\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start Solr\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n- `CONTAINER_NAME`: Container name (default: solr-server)\n- `SOLR_HEAP`: JVM heap size (default: 512m)\n- `SOLR_JAVA_MEM`: Java memory settings (default: -Xms512m -Xmx512m)\n- `SOLR_CORE_NAME`: Default core name (default: mycore)\n\n## Access\n\n- **Port**: 8983 (Docker auto-assigns host port)\n- **Admin UI**: http://localhost:[assigned-port]/solr\n- **Find assigned port**: `docker compose ps` or `docker port solr-server 8983`\n\n### Quick Start Examples\n\n```bash\n# Create a core\ncurl \"http://localhost:8983/solr/admin/cores?action=CREATE&name=products&configSet=_default\"\n\n# Index a document\ncurl -X POST http://localhost:8983/solr/mycore/update?commit=true \\\n  -H \"Content-Type: application/json\" \\\n  -d '[{\"id\":\"1\",\"title\":\"Product Name\",\"description\":\"Product description\"}]'\n\n# Search documents\ncurl \"http://localhost:8983/solr/mycore/select?q=*:*&rows=10\"\n\n# Using container CLI\ndocker exec -it solr-server solr status\ndocker exec -it solr-server solr create_core -c products\n```\n\n### Data Persistence\n\n- **Data Directory**: `./data` - All cores, indexes, and configurations\n- Data persists across container restarts in the repository directory\n\n## Resources\n\n- [Docker Hub - Solr](https://hub.docker.com/_/solr)\n- [Official Solr Documentation](https://solr.apache.org/guide/solr/latest/)\n- [Solr Docker Guide](https://solr.apache.org/guide/solr/latest/deployment-guide/solr-in-docker.html)\n- [Query Syntax Guide](https://solr.apache.org/guide/solr/latest/query-guide/query-syntax-and-parsers.html)"
    },
    {
      "id": "messaging_docker-mailserver",
      "name": "Docker Mailserver",
      "description": "Production-ready fullstack mail server with SMTP, IMAP, anti-spam, and anti-virus protection using configuration files.",
      "category": "messaging",
      "tags": ["messaging", "docker-mailserver"],
      "file_count": 6,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/messaging_docker-mailserver.json",
      "readme": "# Docker Mailserver\n\nProduction-ready fullstack mail server with SMTP, IMAP, anti-spam, and anti-virus protection using configuration files.\n\n## Features\n- Complete mail stack: Postfix (SMTP), Dovecot (IMAP), Rspamd (anti-spam), ClamAV (anti-virus)\n- File-based configuration with no database required\n- Built-in Fail2Ban for brute-force protection\n- SSL/TLS encryption support\n- LDAP authentication support (optional)\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull image and create directories\nup    # Start mail server (auto-creates admin account on first run)\ndown  # Stop and cleanup\n```\n\n### First Run - Automatic Admin Account\nOn first run, an admin mail account is automatically created:\n- **Email**: `admin@your-domain.com` (based on HOSTNAME in .env)\n- **Password**: Random 16-character password\n- **Credentials**: Saved to `./docker-data/dms/admin-credentials.txt`\n\n**Important**: Change this password after first login for security!\n\n## Configuration\nEdit `.env` to customize:\n- `HOSTNAME`: Your mail server hostname (required - e.g., mail.example.com)\n- Security features enabled by default (Rspamd, ClamAV, Fail2Ban)\n\n## Access\n- **SMTP Ports**: 25, 465, 587 (standard mail ports - fixed)\n- **IMAP Port**: 993 (IMAPS)\n- **Note**: Standard mail protocol ports are fixed and cannot be changed\n\n## Important Setup Requirements\nBefore using in production:\n1. **Configure hostname** in `.env` to match your domain (e.g., mail.example.com)\n2. **Start the server** - Admin account is auto-created on first run\n3. **Change default password** - Find credentials in `./docker-data/dms/admin-credentials.txt`\n4. **Setup DNS records**: SPF, DKIM, DMARC for your domain\n5. **Configure SSL/TLS certificates** for secure mail delivery\n6. **Generate DKIM keys** for email authentication\n\n### Managing Mail Accounts\n\n**Quick Management with tool.sh:**\n```bash\n# View auto-generated admin credentials\ncat ./docker-data/dms/admin-credentials.txt\n\n# Add additional mail accounts\n./tool.sh email add user@example.com password123\n\n# Change a password\n./tool.sh email update admin@example.com newpassword\n\n# List all accounts\n./tool.sh email list\n\n# Delete an account\n./tool.sh email del user@example.com\n\n# Add email alias\n./tool.sh alias add info@example.com admin@example.com\n\n# Set mailbox quota\n./tool.sh quota set user@example.com 2G\n\n# Generate DKIM keys (required for production)\n./tool.sh config dkim\n\n# Show all available commands\n./tool.sh help\n```\n\n**Alternative - Direct docker exec:**\n```bash\ndocker exec -it mailserver setup email add user@example.com\ndocker exec -it mailserver setup email list\ndocker exec -it mailserver setup config dkim\n```\n\n## Important Notes\n- **Auto-Generated Admin**: First run creates `admin@your-domain.com` with random password\n- **Credentials File**: `./docker-data/dms/admin-credentials.txt` (change password after first login!)\n- **Fixed Ports**: Mail protocols require standard ports (25, 465, 587, 993)\n- **One Instance Per Machine**: Due to port requirements, only one mail server can run per machine\n- **NET_ADMIN Capability**: Required for Fail2Ban functionality\n- **Data Persistence**: All mail data, state, logs, and config stored in `./docker-data/dms/`\n- **Production Deployment**: Requires proper DNS, SSL/TLS, and configuration - see official docs\n\n## Resources\n- [Official Documentation](https://docker-mailserver.github.io/docker-mailserver/latest/)\n- [Basic Installation Guide](https://docker-mailserver.github.io/docker-mailserver/latest/examples/tutorials/basic-installation/)\n- [Docker Hub](https://hub.docker.com/r/mailserver/docker-mailserver)"
    },
    {
      "id": "messaging_listmonk",
      "name": "Listmonk Newsletter Manager",
      "description": "Self-hosted newsletter and mailing list management platform for email campaigns and subscriber management.",
      "category": "messaging",
      "tags": ["messaging", "listmonk"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/messaging_listmonk.json",
      "readme": "# Listmonk Newsletter Manager\n\nSelf-hosted newsletter and mailing list management platform for email campaigns and subscriber management.\n\n## Features\n- Newsletter and email campaign management with scheduling\n- Subscriber lists with segmentation and custom attributes\n- Rich template editor (WYSIWYG and HTML)\n- Analytics, bounce tracking, and RESTful API\n- Self-hosted with full privacy and data ownership\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start Listmonk (initializes database on first run)\ndown  # Stop and cleanup\n```\n\n### First Run - Initial Setup\nOn first run, the database is automatically initialized:\n- **Database Setup**: Tables and schema created automatically (idempotent)\n- **Admin Account**: You will be prompted to create admin account on first visit\n- **One-Time Setup**: Visit `/admin` path to complete setup\n\n**Important**: Create a strong admin password during first-time setup!\n\n## Configuration\nEdit `.env` to customize:\n- `POSTGRES_USER`: Database username (default: listmonk)\n- `POSTGRES_PASSWORD`: Database password (default: listmonk)\n- `TZ`: Timezone for scheduled campaigns (default: Etc/UTC)\n- `LISTMONK_PORT`: Container port (default: 9000)\n\n## Access\n- **Web Interface**: Auto-assigned port (find with `docker compose ps`)\n  - Admin panel: `http://localhost:<port>/admin`\n  - Public archive: `http://localhost:<port>/`\n- **Find Port**: Run `docker compose ps` and look for mapped port\n- **First Visit**: Visit `/admin` to create your admin account\n- **Startup Time**: Allow ~30 seconds for initialization\n\n## SMTP Configuration (Required!)\n**Critical**: Listmonk requires an external SMTP server to send emails.\n\n### Setup Steps:\n1. **Login** to Listmonk web interface\n2. **Navigate** to Settings → SMTP\n3. **Add SMTP** provider with these details:\n   - Host, Port, Username, Password\n   - TLS/SSL settings\n   - From email address\n4. **Test** the connection before creating campaigns\n\n### Supported SMTP Providers:\n- **Gmail**: smtp.gmail.com:587 (requires App Password)\n- **SendGrid**: smtp.sendgrid.net:587 (API key as password)\n- **Mailgun**: smtp.mailgun.org:587\n- **Amazon SES**: email-smtp.[region].amazonaws.com:587\n- **Self-hosted**: Your own SMTP server\n- See `.env` file for detailed provider configurations\n\n## Campaign Management\n1. **Lists**: Create subscriber lists (Lists → New List)\n2. **Subscribers**: Import CSV (email, name, attributes)\n3. **Templates**: Design email templates\n4. **Campaign**: Create, test, then schedule or send\n5. **Analytics**: Track opens, clicks, and bounces\n\n## Production Setup\n\n1. **Security**\n   - Change admin password immediately after first login\n   - Manage users via Settings → Users\n\n2. **SMTP Configuration**\n   - Use reliable provider (see .env for options)\n   - Configure bounce handling\n   - Test before bulk sends\n\n3. **Email Deliverability**\n   - Set up DNS records (SPF, DKIM, DMARC)\n   - Use dedicated sending domain\n   - Configure rate limiting (Settings → Performance)\n\n4. **Backups**\n   - Regular PostgreSQL backups essential\n   - Data in `./postgres-data/` (subscribers, campaigns, analytics)\n\n## Important Notes\n- **SMTP Required**: Listmonk cannot send emails without SMTP configuration\n- **First-Time Setup**: Admin account created through web interface on first visit to `/admin`\n- **Data Persistence**: Subscriber data and campaigns in `./postgres-data/`\n- **Uploads**: Custom files and images stored in `./uploads/`\n- **Port Assignment**: Container-only port (Docker assigns random host port to avoid conflicts)\n- **Idempotent Setup**: Safe to restart - database won't be recreated\n\n## Resources\n- [Official Documentation](https://listmonk.app/docs/)\n- [Docker Installation Guide](https://listmonk.app/docs/installation/)\n- [API Documentation](https://listmonk.app/docs/apis/)\n- [GitHub Repository](https://github.com/knadh/listmonk)"
    },
    {
      "id": "messaging_rabbitmq",
      "name": "RabbitMQ Message Queue Template",
      "description": "Advanced message queuing protocol (AMQP) broker with management interface.",
      "category": "messaging",
      "tags": ["messaging", "rabbitmq"],
      "file_count": 5,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/messaging_rabbitmq.json",
      "readme": "# RabbitMQ Message Queue Template\n\nAdvanced message queuing protocol (AMQP) broker with management interface.\n\n## Features\n\n- RabbitMQ 3 with management plugin and web UI\n- Persistent message storage with health checks\n- Configurable memory limits and virtual hosts\n- Alpine-based lightweight image\n- Pre-configured admin credentials\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start RabbitMQ server\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n\n- `CONTAINER_NAME`: Container name (default: rabbitmq-server)\n- `RABBITMQ_PORT`: AMQP port (default: 5672)\n- `RABBITMQ_MANAGEMENT_PORT`: Management UI port (default: 15672)\n- `RABBITMQ_DEFAULT_USER`: Admin username (default: admin)\n- `RABBITMQ_DEFAULT_PASS`: Admin password (default: adminPassword123!)\n- `RABBITMQ_DEFAULT_VHOST`: Default virtual host (default: /)\n- `RABBITMQ_MEMORY_LIMIT`: Memory high watermark (default: 0.4)\n\n## Access\n\n- **Management UI**: Port 15672 (Docker auto-assigns host port)\n- **AMQP Port**: Port 5672 (Docker auto-assigns host port)\n- **Default Credentials**: admin / adminPassword123! (set in `.env`)\n- **Find assigned ports**: `docker compose ps`\n\n### Quick Connection Example\n\n```python\nimport pika\n\ncredentials = pika.PlainCredentials('admin', 'adminPassword123!')\nconnection = pika.BlockingConnection(\n    pika.ConnectionParameters('localhost', 5672, '/', credentials)\n)\n```\n\n### Common Commands\n\n```bash\n# Check status\ndocker exec -it rabbitmq-server rabbitmqctl status\n\n# List queues\ndocker exec -it rabbitmq-server rabbitmqctl list_queues\n\n# Create user\ndocker exec -it rabbitmq-server rabbitmqctl add_user myuser mypass\ndocker exec -it rabbitmq-server rabbitmqctl set_permissions -p / myuser \".*\" \".*\" \".*\"\n```\n\n## Resources\n\n- [Official Docker Hub](https://hub.docker.com/_/rabbitmq)\n- [RabbitMQ Documentation](https://www.rabbitmq.com/documentation.html)\n- [AMQP Protocol Specification](https://www.rabbitmq.com/protocols.html)"
    },
    {
      "id": "monitoring_prometheus-grafana",
      "name": "Prometheus + Grafana Monitoring Template",
      "description": "Complete monitoring stack with Prometheus metrics collection and Grafana visualization.",
      "category": "monitoring",
      "tags": ["monitoring", "prometheus-grafana"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/monitoring_prometheus-grafana.json",
      "readme": "# Prometheus + Grafana Monitoring Template\n\nComplete monitoring stack with Prometheus metrics collection and Grafana visualization.\n\n## Features\n\n- Prometheus time-series database with configurable retention\n- Grafana visualization with pre-configured Prometheus data source\n- Node Exporter for system-level metrics (CPU, memory, disk)\n- Persistent data storage with automatic provisioning\n- Ready to add custom application metrics\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start monitoring stack\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n\n**Prometheus Settings:**\n- `PROMETHEUS_PORT`: Web UI port (default: 9090)\n- `PROMETHEUS_RETENTION`: Data retention period (default: 15d)\n\n**Grafana Settings:**\n- `GRAFANA_PORT`: Web UI port (default: 3000)\n- `GRAFANA_ADMIN_USER`: Admin username (default: admin)\n- `GRAFANA_ADMIN_PASSWORD`: Admin password (default: admin)\n- `GRAFANA_ALLOW_SIGN_UP`: Allow user registration (default: false)\n- `GRAFANA_PLUGINS`: Comma-separated plugin list (optional)\n\n**Node Exporter:**\n- `NODE_EXPORTER_PORT`: Metrics endpoint port (default: 9100)\n\n## Access\n\n**Prometheus:**\n- Port: 9090 (Docker auto-assigns host port)\n- No authentication required\n- Find assigned port: `docker compose ps`\n\n**Grafana:**\n- Port: 3000 (Docker auto-assigns host port)\n- Default credentials: admin/admin (change on first login)\n- Prometheus data source pre-configured\n\n**Node Exporter:**\n- Port: 9100 (metrics endpoint)\n- Access metrics at: http://localhost:9100/metrics\n\nTo add custom metrics, edit `prometheus/prometheus.yml` to add scrape targets, then reload config with `curl -X POST http://localhost:9090/-/reload`.\n\n## Resources\n\n- [Prometheus on Docker Hub](https://hub.docker.com/r/prom/prometheus)\n- [Grafana on Docker Hub](https://hub.docker.com/r/grafana/grafana)\n- [Prometheus Documentation](https://prometheus.io/docs/)\n- [Grafana Documentation](https://grafana.com/docs/)\n- [Node Exporter Documentation](https://github.com/prometheus/node_exporter)"
    },
    {
      "id": "networking_cloud-switch",
      "name": "Cloudflare Tunnel Template",
      "description": "Secure tunnel to expose local services via Cloudflare with demo Flask application.",
      "category": "networking",
      "tags": ["networking", "cloud-switch"],
      "file_count": 3,
      "has_readme": true,
      "has_docker": false,
      "status": "skipped",
      "download_url": "templates/networking_cloud-switch.json",
      "readme": "# Cloudflare Tunnel Template\n\nSecure tunnel to expose local services via Cloudflare with demo Flask application.\n\n## Features\n- Cloudflare tunnel (cloudflared) integration for secure remote access\n- QUIC protocol optimization with UDP buffer tuning\n- Demo Flask web application with SQLite database\n- Automated tunnel creation, DNS routing, and cleanup\n- Auto-polling web interface with real-time data display\n\n## Usage\n```bash\nsource Rediaccfile\n./tunnel.sh setup  # One-time: Authenticate with Cloudflare\nprep               # Configure UDP buffers, build image, create tunnel\nup                 # Start Flask application\ndown               # Stop services and cleanup tunnel\n```\n\n## Configuration\nSet environment variable before running:\n- `CLOUDFLARE_TUNNEL_HOST`: Domain for tunnel (default: demo.rediacc.com)\n\nExample:\n```bash\nexport CLOUDFLARE_TUNNEL_HOST=\"myapp.example.com\"\n```\n\nThe tunnel automatically:\n- Creates unique tunnel per hostname\n- Configures DNS routing\n- Proxies to local Flask app on port 5000\n\n## Access\n- **Service Port**: 5000 (internal, accessed via Cloudflare tunnel URL)\n- **Tunnel URL**: https://[CLOUDFLARE_TUNNEL_HOST]\n- **Authentication**: Requires Cloudflare account (configured during `setup`)\n- **View tunnel status**: `docker ps` (look for cloudflared containers)\n\n## Resources\n- [Cloudflare Tunnel Documentation](https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/)\n- [cloudflared Docker Hub](https://hub.docker.com/r/cloudflare/cloudflared)\n- [QUIC Protocol UDP Optimization](https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes)"
    },
    {
      "id": "platforms_gitlab",
      "name": "GitLab CE (Community Edition) Template",
      "description": "Self-hosted Git repository manager with CI/CD, issue tracking, and more.",
      "category": "platforms",
      "tags": ["platforms", "gitlab"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/platforms_gitlab.json",
      "readme": "# GitLab CE (Community Edition) Template\n\nSelf-hosted Git repository manager with CI/CD, issue tracking, and more.\n\n## Features\n- Web-based Git repository management with built-in CI/CD pipelines\n- Issue tracking, project management, and wiki documentation\n- Container registry and merge request workflows\n- Persistent storage for repositories, configs, and logs\n- Minimum 4GB RAM required (8GB recommended)\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start GitLab CE\ndown  # Stop and cleanup\n```\n\n**Initial Setup:**\n1. Wait 5-10 minutes for first-time initialization\n2. Get root password: `docker exec -it gitlab grep 'Password:' /etc/gitlab/initial_root_password`\n3. Login at http://localhost with username `root`\n4. Change password immediately\n\n## Configuration\nEdit `.env` to customize:\n- `CONTAINER_NAME`: Container name (default: gitlab)\n- `GITLAB_HOSTNAME`: Hostname for GitLab (default: localhost)\n- `GITLAB_HTTP_PORT`: HTTP port (default: 80)\n- `GITLAB_HTTPS_PORT`: HTTPS port (default: 443)\n- `GITLAB_SSH_PORT`: SSH port for Git operations (default: 2222)\n- `GITLAB_OMNIBUS_CONFIG`: Additional Omnibus configuration (see docs)\n\n**Common Configuration Examples:**\n```bash\n# Enable container registry\nGITLAB_OMNIBUS_CONFIG=\"registry_external_url 'http://localhost:5000'; gitlab_rails['registry_enabled'] = true;\"\n\n# Reduce memory usage\nGITLAB_OMNIBUS_CONFIG=\"postgresql['shared_buffers'] = '256MB'; sidekiq['concurrency'] = 5; prometheus_monitoring['enable'] = false;\"\n```\n\n## Access\n- **Web Interface**: http://localhost (or configured HTTP port)\n- **Default username**: root\n- **Initial password**: See `./config/initial_root_password` or extract via docker exec\n- **Git SSH**: `git clone ssh://git@localhost:2222/username/project.git`\n- **Git HTTP**: `git clone http://localhost/username/project.git`\n- **Find ports**: `docker compose ps`\n\n**Quick Commands:**\n```bash\n# Create backup\ndocker exec -t gitlab gitlab-backup create\n\n# Monitor logs\ndocker logs -f gitlab\n\n# Access GitLab Rails console\ndocker exec -it gitlab gitlab-rails console\n```\n\n## Resources\n- [Official Docker Hub](https://hub.docker.com/r/gitlab/gitlab-ce)\n- [Official Documentation](https://docs.gitlab.com/ee/install/docker.html)\n- [GitLab Runner Setup](https://docs.gitlab.com/runner/install/docker.html)\n- [Omnibus Configuration](https://docs.gitlab.com/omnibus/settings/)"
    },
    {
      "id": "platforms_nextcloud-aio",
      "name": "Nextcloud All-in-One",
      "description": "Official Nextcloud All-in-One deployment with master container orchestration for complete self-hosted cloud platform.",
      "category": "platforms",
      "tags": ["platforms", "nextcloud-aio"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/platforms_nextcloud-aio.json",
      "readme": "# Nextcloud All-in-One\n\nOfficial Nextcloud All-in-One deployment with master container orchestration for complete self-hosted cloud platform.\n\n## Features\n- Master container manages entire Nextcloud stack (web, database, cache, optional services)\n- Built-in PostgreSQL, Redis, Apache with optimized PHP configuration\n- Automatic HTTPS with Let's Encrypt certificate management\n- Optional components: Collabora Office, Talk, ClamAV, Full-text Search\n- Web-based management interface with backup/restore capabilities\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull master container image\nup    # Start Nextcloud AIO\ndown  # Stop Nextcloud AIO\n```\n\n## Configuration\nEdit `.env` to customize:\n- `DOCKER_HOST`: Docker socket path (default: `/var/run/docker.sock`)\n  - Use custom path for systems with per-repository Docker instances\n- `NEXTCLOUD_DATADIR`: Custom data directory location (optional)\n- `APACHE_PORT`: Custom Apache port binding (default: auto-assigned)\n- `APACHE_IP_BINDING`: IP address binding for reverse proxy setups (optional)\n\n## Access\n- **Management Interface**: Auto-assigned port (find with `docker compose ps`)\n  - Default: `https://localhost:<port>` (self-signed certificate)\n- **Initial Setup**: Follow web interface wizard to configure domain, admin account, and optional services\n- **Nextcloud Access**: Port 443 (HTTPS) after configuration via management interface\n\n## Important Notes\n- **Docker Socket**: This template requires Docker socket access for the master container to orchestrate other containers\n  - Configurable via `DOCKER_HOST` environment variable\n  - Defaults to `/var/run/docker.sock` for standard Docker installations\n- **Single Domain**: AIO requires one domain for all services (simplifies SSL/TLS management)\n- **Volume Requirements**: Uses named volume with local bind driver pointing to `./aio-config` for portability\n- **First Run**: Complete setup via web interface - configuration is managed through UI, not environment variables\n\n## Resources\n- [Official Documentation](https://github.com/nextcloud/all-in-one)\n- [Docker Hub](https://github.com/nextcloud/all-in-one/pkgs/container/all-in-one)\n- [Nextcloud Homepage](https://nextcloud.com)"
    },
    {
      "id": "platforms_nginx",
      "name": "Nginx Template",
      "description": "Minimal Nginx web server deployment.",
      "category": "platforms",
      "tags": ["platforms", "nginx"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/platforms_nginx.json",
      "readme": "# Nginx Template\n\nMinimal Nginx web server deployment.\n\n## Features\n- Latest Nginx stable release\n- Single command deployment\n- Lightweight and fast HTTP server\n- Auto-cleanup on container stop\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull Nginx image\nup    # Start Nginx server\ndown  # Stop and cleanup\n```\n\n## Configuration\nThis template uses a minimal configuration:\n- **Port**: 80 (Docker auto-assigns host port)\n- **Container**: Runs in detached mode with auto-removal\n\n## Access\n- **Port**: 80 (Docker auto-assigns host port)\n- **Find assigned port**: `docker ps | grep rediacc-nginx`\n- **Default page**: Access via `http://localhost:[assigned-port]`\n\n## Resources\n- [Official Docker Hub](https://hub.docker.com/_/nginx)\n- [Official Documentation](https://nginx.org/en/docs/)"
    },
    {
      "id": "platforms_wordpress",
      "name": "WordPress Template",
      "description": "Full WordPress installation with MySQL database.",
      "category": "platforms",
      "tags": ["platforms", "wordpress"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "active",
      "download_url": "templates/platforms_wordpress.json",
      "readme": "# WordPress Template\n\nFull WordPress installation with MySQL database.\n\n## Features\n- Latest WordPress version with MySQL 8.0 backend\n- Persistent storage for content, uploads, and database\n- Auto-restart on failure for reliability\n- Simple setup with guided installation wizard\n\n## Usage\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start WordPress and MySQL\ndown  # Stop and cleanup\n```\n\n## Configuration\nEdit `.env` to customize:\n- `REDIACC_SDK_REPO_INIT_SIZE`: Initial repository size (default: 1G)\n- `REDIACC_SDK_REPO_RESIZE_SIZE`: Resize amount when full (default: empty)\n\nDatabase credentials are configured in `docker-compose.yaml`:\n- Database name: `exampledb`\n- Database user: `exampleuser`\n- Database password: `examplepass`\n\n## Access\n- **Port**: 80 (Docker auto-assigns host port)\n- **Credentials**: Complete installation wizard on first visit\n- **Find assigned port**: `docker compose ps`\n\nVisit the assigned port and follow the WordPress installation wizard to set up your admin account.\n\n## Resources\n- [Official Docker Hub](https://hub.docker.com/_/wordpress)\n- [Official Documentation](https://wordpress.org/support/)"
    },
    {
      "id": "search_elasticsearch",
      "name": "Elasticsearch Search Engine Template",
      "description": "Full-text search and analytics engine with Kibana visualization interface.",
      "category": "search",
      "tags": ["search", "elasticsearch"],
      "file_count": 4,
      "has_readme": true,
      "has_docker": true,
      "status": "skipped",
      "download_url": "templates/search_elasticsearch.json",
      "readme": "# Elasticsearch Search Engine Template\n\nFull-text search and analytics engine with Kibana visualization interface.\n\n## Features\n\n- Elasticsearch 8.11.0 with single-node development setup\n- Kibana 8.11.0 web UI for data visualization and management\n- Configurable JVM heap size and cluster settings\n- Persistent data storage with health checks\n- Security disabled by default for easy local development\n\n## Usage\n\n```bash\nsource Rediaccfile\nprep  # Pull images and create directories\nup    # Start Elasticsearch and Kibana\ndown  # Stop and cleanup\n```\n\n## Configuration\n\nEdit `.env` to customize:\n- `CONTAINER_NAME`: Container name (default: elasticsearch)\n- `ES_PORT`: HTTP API port (default: 9200)\n- `ES_TRANSPORT_PORT`: Transport port (default: 9300)\n- `ES_CLUSTER_NAME`: Cluster name (default: docker-cluster)\n- `ES_HEAP_SIZE`: JVM heap size (default: 512m)\n- `ES_SECURITY_ENABLED`: Enable security (default: false)\n- `KIBANA_PORT`: Web UI port (default: 5601)\n- `KIBANA_SERVER_NAME`: Server name (default: kibana)\n\n## Access\n\n**Elasticsearch API**: `http://localhost:9200`\n```bash\n# Check cluster health\ncurl http://localhost:9200/_cluster/health?pretty\n\n# Index a document\ncurl -X POST \"localhost:9200/my-index/_doc\" -H 'Content-Type: application/json' -d'\n{\n  \"title\": \"Sample Document\",\n  \"content\": \"This is a test document\"\n}'\n\n# Search documents\ncurl -X GET \"localhost:9200/my-index/_search?q=test&pretty\"\n```\n\n**Kibana Web Interface**: `http://localhost:5601`\n- No authentication required (security disabled)\n\n**Find assigned ports**: `docker compose ps`\n\n## Resources\n\n- [Elasticsearch Docker Hub](https://hub.docker.com/_/elasticsearch)\n- [Elasticsearch Documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\n- [Kibana Documentation](https://www.elastic.co/guide/en/kibana/current/index.html)"
    }
  ]
}
